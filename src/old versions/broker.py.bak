"""Brokers Queries to downstream logic based on Query.ProcessState.

This script is designed to be executed as a long running service.

TODO: Consider shifting to a daemonize approach to manage this process.
"""
import threading
from status.status import APIRepository
from datetime import datetime
import logging
from models import compute_matches

LOOP_EXECUTION_TIME = 10.0  # In seconds
LOG_NAME = 'logs/query_broker_{0}.log'.format(
    datetime.now().strftime("%Y_%m_%d"))
FORMAT = '%(asctime)s; %(levelname)s; {%(module)s}; [%(funcName)s] %(message)s'

logging.basicConfig(
    format=FORMAT,
    level=logging.DEBUG,
    handlers=[logging.FileHandler(LOG_NAME),
              logging.StreamHandler()])


def main():
    # Execute long pooling loop
    processing = False
    try:
        queryStatus = APIRepository()
        # create a new thread.  There will be a max of 3 threads at any one time.
        threading.Timer(LOOP_EXECUTION_TIME, main).start()
        if not processing:
            processing = True
            result = queryStatus.getStatus()

            if result["new"]:
                compute_matches.new_matches(result["new"])
            if result["revise"]:
                compute_matches.revised_matches(result["revise"], [])
            processing = False
    except Exception as e:
        logging.error(e)
    finally:
        processing = False


if __name__ == '__main__':
    main()
